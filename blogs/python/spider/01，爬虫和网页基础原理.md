---
title: 爬虫和网页基础原理
date: 2020-03-15
tags:
 - scrapy
 - spider
categories:
 - python
---

爬虫和网页基础原理

## 一、课程安排

- 爬虫基础简介
- 爬虫入门
- 爬虫框架scrapy
- 分布式爬虫
- 爬虫部署
- 反爬相关

## 二、一次Http请求过程

1. 域名解析
2. 发起Tcp3次握手（打电话）
3. 建立TCP连接后发起Http请求
4. 服务器响应请求，返回结果
5. 浏览器解析html代码中的资源，例如js，css，img等
6. 浏览器对页面进行渲染并呈现给用户

爬虫的爬取对象

- 本质上爬虫爬取就是网页上的内容

超文本是什么？

- 我们在网页上看到的所有内容都是超文本

## 三、网页组成

整个互联网有无数个网页，这些网页的样式都是不一样的（移动端、web端），但是不管什么样网页，都离不开web三剑客，HTML，CSS，JavaScript。

- HTML(超文本标记语言)

一般是成对出现

HTML由许多标签组成，每个标记都用不同的标签表示，比如，图片标签用img，文字用p标签或a标签，输入框用input标签表示等，HTML定义了一个网页的基本骨架。在网页中看到的文本、图片、视频、声音都是由HTML实现的，HTML文档其后缀为.HTML

- CSS（层叠样式表）

CSS用与处理网页中的样式，样式是指：网页中文字的大小、颜色、元素之间的距离、排列方式等，CSS可以让网页看起来更漂亮、一般使用来与HTML配合使用的，CSS其后缀是由.css结尾的。

- JS（JavaScript）

js是一种脚本语言，HTML和CSS配合使用提供给用户的只是一种静态信息，缺少交互性，我们通常在网页中可能看到一些交互和动画效果，比如进度条，提示框，轮播图等，这都是由js实现的，比较有代表性的 知乎的下拉加载

为什么要学习前端网页的知识？

学习HTML、CSS是为了在爬虫过程中对数据的过滤、提取，而学习JS是为了在以后做爬虫的时候，遇到动态渲染的、或者JS加密验证的时候，知道如何去处理这些难题。不要求会写网页、但是至少要看的懂前端的代码，看到前端代码时、脑子里大概有个印象这端代码是干嘛用的，这就是现在讲前端基础知识的目的

爬虫学习的两个重点：网络请求和页面解析

- 浏览器调试工具

- requests（请求）和response（相应）：

请求包含了请求头和请求体

1. url组成

   请求方法

   get、post、delete、head、update

2. 状态码

   - 2xx：成功

   - 3xx：重定向
   - 4xx：请求错误，服务器不接受
   - 5xx：服务器内部错误

3. Remote Address

   - 域名对应的ip地址

   - 请求参数

   - 响应包含了响应头和响应体

   - 响应头

   - 响应体（超文本内容）

4. 页面解析：

   - 在html中过滤不需要的内容，提取需要的内容

## 四、爬虫的工作流程：

1，获取网页：（确定Url）

​		爬虫首先要做的工作就是获取网页，在代码中就是获取网页的源代码，源代码里包含了网站的所有可见数据，所以只要把源代码获取下来，就可以从中提取到		想	要的信息

2，提取数据：

​		获取网页源代码后，接下来就是分析网页源代码，从中提取我们需要的信息

3，保存数据：

​		提取数据后，我们一般会将提取到的数据保存到某处以便后续使用(持久化)

## 五、爬虫的分类：

1. 通用爬虫：

   ​	常见的搜索引擎就是一个通用爬虫。必须遵循规则：Robots协议

2. 聚焦爬虫：

   ​	针对于某一需求编写的爬虫程序。

## 六、爬虫违法吗(爬虫协议)？

​	如果爬取的是公开的数据，那么和浏览器访问没有本质的区别

​	如果没有遵循爬虫协议，对网站造成负担，那么就可能被认定为违法操作

​	robots.txt

常见的反爬虫

​	UA标识，代理ip，验证码，动态加载，内容加密

爬虫目标分类： web端

移动端

调试工具：fiddler、postman
