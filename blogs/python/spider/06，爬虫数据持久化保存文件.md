---
title: 爬虫数据持久化保存文件
date: 2020-03-22
tags:
 - scrapy
 - spider
categories:
 - python
---

## 一、保存文本文件

### 写入文本文件

1. 打开文件

   ``` python
   f = open(file='fileNmae.txt', mode='a')
   ```

2. 写入内容

   ``` python
   f.write('hello world')
   ```

3. 关闭文件

   ``` python
   f.close()
   ```

4. 使用with

   ``` python
   with open(file='fileName.txt', mode='a')as f:
       f.write('hello world')
   ```

5. 解码方式

   ``` python
   f = open(file='fileNmae.txt', mode='a', encoding='utf-8')
   f.write('中国')
   ```

### 读取文本文件

``` python
with open(file='fileName.txt', mode='r', encoding='utf-8')as f:
    context = f.read()
print(context)
```



## 二、保存Json文件

### 写入Json文件

``` python
import json

data = {'名字': 'lopo','年龄': 18}

x = open('demo.json', mode='a', encoding='utf-8')
x.write(json.dumps(data, ensure_ascii=False))
x.close()
```

### 读取Json文件

``` python
import json

x = open('demo.json', 'r', encoding='utf-8')
context = json.loads(x.read())
x.close()
print(context)
print(type(context))

```

## 三、保存图片

### 写入图片

```python
import requests
import uuid

img = requests.get('http://img.netbian.com/file/2020/1102/5fff60c5b3bb235d15ced6f1a98a25a6.jpg').content

name = str(uuid.uuid1()) + '.jpg'

with open(name, 'wb') as f:
    f.write(img)
```

### 读取图片

``` python
with open(name, 'rb') as f:
    context = f.read()
    # 输出16进制内容
    print(context)
```

## 四、保存视频

### 写入图片

```python
import requests
import uuid

img = requests.get('https://video.huxiucdn.com/mda-kk2jiuaiuqnj8viv/mda-kk2jiuaiuqnj8viv.mp4').content

name = str(uuid.uuid1()) + '.mp4'

with open(name, 'wb') as f:
    f.write(img)
```

## 五、保存Excel表

### 写入

``` python
import xlwt

book = xlwt.Workbook(encoding='ascii')
sheet = book.add_sheet('info')

hear_info = ['name', 'age']
for i, info in enumerate(hear_info):
    sheet.write(0, i, info)
book.save('info.xls')
```

### 读取

``` python
import xlrd
data = xlrd.open_workbook(filename='info.xls')
table = data.sheet_by_name(sheet_name="info")

for rowNum in range(table.nrows):
	print(table.row_values(rowNum))
```



